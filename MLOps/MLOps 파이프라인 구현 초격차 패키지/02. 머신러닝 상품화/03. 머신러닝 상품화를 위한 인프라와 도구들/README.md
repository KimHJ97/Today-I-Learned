# MLOps 구현을 위한 인프라 요소

## MLOps 주요 인프라 요소

 - __Storage__
    - 데이터의 저장, 백업, 복구 기능을 제공
    - 예시 : Amazon S3는 대규모 데이터를 저장하고 접근할 수 있는 클라우드 기반 서비스
    -  MLOps 예시 : 대규모 이미지 데이터셋을 S3 버킷에 저장하여 머신러닝 모델 트레이닝에 활용
 - __Computing Resources (컴퓨팅 리소스)__
    - 데이터 처리, 분석, 모델 트레이닝에 필요한 컴퓨팅 파워를 제공
    -  예시 : Google Cloud의 Computing Engine은 사용자가 필요에 따라 확장 가능한 컴퓨팅 리소스를 제공
    - MLOps 예시 : Computing Engine에서 GPU를 활용해 복잡한 머신러닝 모델을 빠르게 트레이닝
 - __환경 관리 툴__
    - 프로젝트별 독립적인 환경을 제공하는 패키지 및 환경 관리 시스템
    -  MLOps 예시 : Conda 환경을 사용해 팀 내 다양한 머신러닝 프로젝트의 의존성을 관리
 - __Container (컨테이너)__
    - 애플리케이션과 그 의존성을 패키지화하여 일관된 환경에서 실행할 수 있도록 지원
    - 예시 : Docker는 애플리케이션을 컨테이너화하여 다양한 환경에서 실행할 수 있게 함
    - MLOps 예시 : Docker 컨테이너를 사용해 모델 트레이닝 환경을 일관되게 유지
 - __Orchestrator (오케스트레이터)__
    - 여러 컨테이너의 배포, 확장, 네트워킹을 관리
    - 예시 : Kubernetes는 대규모 컨테이너화된 애플리케이션의 관리와 조정을 담당
    - MLOps 예시 : Kubernetes를 사용해 여러 모델 서빙 컨테이너를 자동으로 스케일링 및 관리
 - __Workflow Management__
    - 작업을 효율적으로 컴퓨팅 리소스에 할당하고 실행
    - 예시 : Apache Airflow는 복잡한 워크플로우 관리 및 스케쥴링에 사용
    - MLOps 예시 : Airflow를 사용해 일일 데이터 처리 및 모델 트레이닝 작업을 자동화
 - __CI/CD__
    - 모델 개발 및 테스트 주기를 단축시켜, 빠른 반복을 가능하게 하는 도구
    - MLOps 예시 : 새로운 모델 알고리즘 코드가 업데이트되면, 자동으로 모델을 학습/평가/검증하여서 프로덕션 환경으로 릴리즈
 - __버전 관리__
    - 소프트웨어 프로젝트의 다양한 요소를 버전 관리 진행
    - MLOps 예시 : 이전에 개발된 모델 재현을 위해 원하는 버전의 데이터, 코드를 활용
 - __HTTP & REST API__
    - 다른 시스템과의 통신을 위한 표준 프로토콜 및 인터페이스
    - MLOps 예시 : 외부에서 모델 트레이닝 task를 수행하기 위해 REST POST API로 요청


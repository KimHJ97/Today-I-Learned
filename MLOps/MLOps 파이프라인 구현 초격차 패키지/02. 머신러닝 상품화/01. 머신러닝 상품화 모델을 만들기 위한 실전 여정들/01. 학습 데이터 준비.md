# 학습 데이터 준비

## 데이터 유형

### 정형 데이터

구조화된 데이터로 표 형태로 표현되며 고정된 스키마를 갖는다.  
데이터베이스, 스프레드시트 및 CSV 파일과 같은 데이터 소스에서 얻음  
 - 고정된 스키마: 정해진 필드 및 데이터 형식을 갖는다.
 - SQL 쿼리 사용 가능: 데이터베이스 관리 시스템에서 SQL 쿼리를 통해 데이터 검색 및 조작 가능
 - 쉬운 분석: 데이터 분석 도구와 머신러닝 모델에 쉽게 적용 가능

<br/>

### 비정형 데이터

구조가 없거나 매우 제한적인 구조를 가지지 않는 데이터로 텍스트, 이미지, 오디오, 비디오 같은 형태를 갖는다.  
 - 구조가 없음: 데이터는 자유 형식이며, 특정 구조를 따르지 않는다.
 - 고도의 전처리 필요: 데이터 전처리 및 특징 추출이 고도의 기술로 필요하며, 자연어 처리/컴퓨터 비전 및 음성 처리 기술을 활용해야 함


### 반정형 데이터
구조가 명확하게 정의되지 않은 데이터로 일부 구조화된 정보를 갖는다.  
XML, JSON, HTML과 같은 마크업 언어를 사용하여 주로 표현  
예시: 웹 스크래핑 데이터, 기업 문서 데이터 등  
 - 일부 구조화된 정보: 데이터 내에 구조가 정확히 정의되지 않았지만 일부 마크업 또는 태그를 갖는다.
 - 데이터 파싱 필요: 데이터 파싱을 통해 의미 있는 정보 추출이 필요
 - 유연성: 데이터 형식이 더 유연하며 새로운 정보를 추가하거나 수정하기 용이함

<br/>

### 실시간 데이터

데이터를 실시간으로 분석하고 수행해야 하는 데이터를 의미한다.  
이미 저장된 것이 아닌, 실시간으로 데이터가 수집되는 것으로 유튜브 시청 데이터, 금융 거래 데이터, IoT 센서 데이터 등이 해당된다.  

금융 거래의 경우 주식 거래 및 금융 거래 데이터는 실시간으로 처리되어야 하며 시장 조건에 따라 신속한 결정이 필요하다. IoT 센서 데이터의 경우 환경 데이터를 센싱할 때 실시간으로 분석하여 환경 상태를 모니터링 하거나 경고를 생성해야 한다.  

 - `스트리밍 데이터`
    - 지속적으로 생성되고 전송되는 데이터 스트림을 나타냄
    - 시간이 지나면서 변경되며 새로운 데이터가 계속해서 이전 데이터에 추가된다.
    - __무한한 데이터 스트림__: 데이터의 끝이 없고 지속적으로 생성되므로 스트리밍 데이터를 처리하기 위한 특수한 방법 필요
    - __실시간 분석__: 데이터가 도착하자마자 분석되며, 지연이 발생하지 않아야 함
 - `IoT 데이터`
    - 다양한 종류의 데이터가 복합적으로 스트리밍 형식으로 수집
    - 작은 Edge Device에서 수집되는 경우가 많음
    - __대량 데이터 처리__: 일반적인 데이터들보다도 상대적으로많은 데이터를 저장 및 처리할 수 있어야 함
    - __다양한 데이터 형식__: 다양한 형식과 프로토콜로 데이터가 전송되기 때문에, 데이터 변환 및 표준화가 필요할 수 있음

<br/>

### 데이터 저장과 관리

 - `DBMS`
    - 구조화된 데이터를 효율적으로 저장, 관리 및 검색하기 위한 소프트웨어 시스템
    - SQL을 사용하여 데이터베이스에 대한 쿼리 및 조작을 지원
    - MySQL, PostgreSQL 등
 - `NoSQL DB`
    - 정형 데이터 외에도 반정형 및 비정형 데이터를 저장하고 관리하기 위한 데이터베이스
    - 데이터 형식 유연성 제공, 대량 데이터 처리와 분산 환경 확장 가능
    - MongoDB, Cassandra, Redis 등
 - `Data Lake`
    - 다양한 비구조화 데이터를 저장하는 시스템으로 원시 데이터를 보관하고 나중에 분석 및 처리에 활용
    - 스키마의 유연성을 제공하고 나중에 정의되거나 변경될 수 있으며, 쉽게 새로운 데이터 형식을 수용할 수 있음
 - `Data Warehouse`
    - 다양한 데이터 원본에서 데이터를 추출, 변환 및 로드(ETL)하여 중앙 집계 및 분석을 위한 중앙 데이터 저장소를 만드는 시스템
    - 주로 정형 데이터 중심. 구조화된 데이터를 저장하고 분석

<br/>

### 데이터 버전 관리

데이터의 변경 이력을 추적하고 이전 상태로 롤백할 수 있는 프로세스  
데이터의 무결성과 안전성을 보장하며, 잘못된 변경으로 인한 문제를 예방  

 - `Git-LFS 혹은 Feature Store`
    - Git Large File Storage는 Git 확장 도구로 대용량 데이터 파일을 관리할 수 있음
    - Feature Store는 Feature(Data 가공된 버전)의 버전 관리를 지원
 
<br/>

## 데이터 샘플링

데이터 샘플링은 큰 데이터 집합에서 작은 부분 집합을 추출하는 프로세스이다. 통계 및 데이터 분석 분야에서 사용되는 일반적인 기술로, 데이터의 일부를 조사하고 전체 데이터 집합에 대한 결론을 도출하는 데 활용된다.  
 - 자원 및 시간 절약: 전체 데이터 집합을 처리하거나 분석하는 데 걸리는 시간과 자우너을 절약. 대규모 데이터 집합에서 무작위로 추출된 샘플은 대부분의 데이터를 다루지 않아도 결과를 얻을 수 있다.
 - 품질 향상: 데이터 샘플링은 데이터 품질을 향상시키는 데 도움. 이상치나 오류를 탐지하고 데이터 정제를 수행하기 위해 데이터의 작은 부분을 확인
 - 통계적 추론: 데이터 샘플을 사용하면 통계적 추론을 수행. 추출된 샘플을 기반으로 모집단에 대한 통계적 추론을 수행하여 일반적인 패턴, 평균, 분포 등을 파악한다.
 - 데이터 시각화: 데이터 샘플을 사용하여 데이터 시각화를 수행하면 데이터를 더 잘 이해하고 시각적으로 표현할 수 있음. 이를 통해 패턴, 관계 및 트렌드를 시각적으로 파악 가능하다.
 - 데이터 테스트: 데이터 샘플링은 새로운 데이터 수집 및 분석 기술의 테스트와 실험에 유용. 더 많은 데이터를 수집하기 전에 시스템 및 알고리즘을 테스트 가능하다.

<br>

### 데이터 샘플링 종류

 - `Random Sampling`
    - 무작위로 데이터 집합에서 샘플을 선택하는 방법
    - 각 데이터 포인트가 선택될 확률은 동일하며, 편향이 적게 대표성 있는 샘플을 얻을 수 있음
 - `Stratified Sampling`
    - 데이터를 계층적으로 분류한 후, 각 계층에서 샘플을 추출하는 방법
    - 각 계층의 특성을 고려하여 샘플을 얻기 위해 사용
    - 예를 들어, 남성과 여성의 성별에 따라 샘플을 추출할 떄 사용
 - `Cluster Sampling`
    - 데이터를 여러 그룹 또는 Cluster로 나누고, 몇 개의 Cluster를 무작위로 선택한 후 선택된 Cluster 내의 모든 데이터를 포함하는 방법
    - 데이터가 고루 분포되지 않은 경우에 유용
    - 데이터가 클러스톨 그룹화 될 떄 사용
 - `Weight Sampling`
    - 데이터 포인트에 가중치를 할당하고 이러한 가중치를 기반으로 샘플을 추출하는 방법
    - 데이터 포인트에 할당된 가중치는 해당 데이터 포인트의 중요성을 나타내며, 중요한 데이터는 더 자주 선택될 가능성이 높음
 - `Importance Sampling`
    - 확률 분포에 기반한 통계 샘플링 기법
    - 베이지안 추론, 몬테 카를로 시뮬레이션, 결합 확률 분포의 추정 등

<br/>

### 데이터 샘플링 고려 사항

 - `편향과 오차 관리`
    - 특정 데이터 세트에 대한 과소 또는 과대 표현이 일어나지 않도록 샘플링을 선정
    - 샘플링 과정 속에서 무작위성에 의한 변동이 많지 않도록 샘플링을 선정
 - `데이터 샘플링 샘플 크기 및 신뢰 수준`
    - 데이터 샘플링에서 샘플 크기와 신뢰 수준은 중요한 결정 사항
    - 통계적 방법을 사용하여 샘플 크기 및 신뢰 수준을 설정
    - 모집단의 크기, 표본 분포의 변동성, 회귀 사건의 발생률 및 원하는 신뢰 수준 등을 고려해서 샘플 크기를 선정할 수 있음

<br/>

## 라벨링과 이에 따른 모델 학습 유형

라벨링 혹은 레이블링이라 불리며, 특정 객체에 의미를 부여하는 프로세스를 의미한다.  
데이터 라벨링이란 기계 학습 및 딥러닝 모델을 훈련하기 위해 필요한 데이터에 의미를 부여하는 과정을 말한다. 즉, 데이터에 주석을 달거나 레이블을 지정하여 의미를 부여하는 과정이다. 이를 통해, 모델이나 컴퓨터가 데이터를 이해하고 원하는 작업을 수행할 수 있도록 돕는 중요한 단계로 컴퓨터가 데이터를 처리하고 해석할 수 있는 방식으로 데이터를 변환하는 작업을 말한다.  

 - `Image Labeling`
    - 객체 인식, 세그멘테이션, 특징 포인트 지정, 이미지 분류 등의 다양한 작업에서 필요로 함
    - 개와 고양이 이미지를 Labeling하여 모델이 이 두 동물을 구별할 수 있도록 함
 - `Text Labeling`
    - 텍스트 분류, 감정 분석, 주관적 의견 분석, 키워드 추출 및 개체명 인식
    - 텍스트 문서에 글의 주제, 감정, 주요 키워드 등을 Labeling하여 모델이 텍스트를 이해하도록 도움
 - `Audio Labeling`
    - 음성 인식, 음악 분류, 화자 인식
    - Audio에 발화된 단어, 음악 트랙의 장르, 음성 신호의 특징을 Labeling하여 모델이 오디오를 이해하도록 도움

<br/>

### 다양한 도메인의 라벨링 데이터

```
★ 의료 분야
 - 의료 영상 데이터의 라벨링
 - 종양 발견, 질병 분류 및 환자 정보 관리에 사용

★ 자연어 처리 (NLP)
 - 텍스트 라벨링
 - 텍스트 분류, 기계 번역, 자동 질문 응답 시스템에서 활용

★ 자율 주행 자동차
 - 센서 데이터의 라벨링
 - 도로 상황 이해 및 자율 주행일 지원

★ 환경 모니터링
 - 환경 데이터 라벨링
 - 환경 상태 모니터링 및 예측
```

<br/>

### 라벨링과 AI 모델 학습 유형

#### Supervised Learning

데이터에 모든 라벨링이 존재한 상태에서의 Learning 방식  
모델은 라벨링된 데이터를 기반으로 학습하여 이후 새로운 입력 데이터에 대한 예측을 수행할 수 있음  
모델은 라벨링된 데이터를 활용하여 데이터 패턴을 학습

 - `Classification and Regression`
    - Classfication: 데이터를 여러 클래스 또는 범주로 분류하는 작업을 수행. 예를 들어, 스팸과 정상 이메일을 구분하는 문제 해결
    - Regression: 연속적인 출력 값을 예측하는 작업을 수행. 예를 들어, 주택 가격 예측과 주식 가격 예측 등의 문제 해결

<br/>

#### Semi-Supervied Learning

일부 데이터만 라벨링이 존재하며, 나머지는 라벨링이 존재하지 않는 상황에서의 Learning 방식  
모델은 라벨링된 데이터를 통해 스스로 특징을 학습하고, 그 특징을 활용하여 라벨이 없는 데이터를 예측  


 - `Self Training`
    - 초기에 라벨링된 데이터로 모델을 훈련한 후, 모델이 높게 예측한 라벨링이 없는 데이터에 적용하여 라벨링을 하고 모델을 학습하는 과정을 반복
 - `Co Training`
    - 데이터를 여러 독립적인 부분 집합 또는 도메인으로 나누어 모델을 학습하여, Semi-Supervised 학습에서의 데이터 부족 문제를 해결
    - 초기 데이터: 데이터를 여러 부분으로 나눔
    - 초기 모델: 독립된 모델을 각 부분 데이터에 대해 각각 학습. 모델 A는 하나의 관점으로 학습하고, 모델 B는 다른 관점으로 학습
    - 정보 교환: 모델 A와 모델 B가 각자 학습한 결과물을 공유하며 서로의 예측을 보완
 - `Multi View Learning`
    - 데이터를 여러 다른 관점 또는 특성을 나누어 모델을 학습
    - 데이터의 다양한 특성이 중요한 경우에 유용
    - 데이터 분할: 데이터를 여러 부분 또는 관점으로 분할
    - 모델 학습: 각 관점 또는 특성에 대해 별도의 모델을 학습
    - 결합: 각 관점에서 얻은 정보를 종합하여 모델을 결합

<br/>

#### Self-Supervised Learning

데이터에 모든 라벨링이 존재하지 않으며, 모델이 스스로 학습할 수 있도록 설계된 Learning 방식  
데이터 내에서 숨겨진 정보를 활용하여 모델을 학습  

 - `Auto Encoder`
    - 입력 데이터를 압축하고 다시 복원하는 네트워크 아키텍처로 Encoder와 Decoder로 구성
    - 모델은 입력 데이터를 압축하고 복원하는 과정에서 정보를 학습
    - 학습이 완료되면 Encoder의 중간 embedding(특성)을 활용하여 다른 작업에 모델을 Transfer 할 수 있음
 - `Masked Language Model`
    - 일부 단어를 가리고 해당 단어를 예측하는 Task를 활용
    - 모델은 문맥을 이해하고 숨겨진 단어를 예측하기 위해 단어 간의 관계를 학습
    - 자연어 처리 모델의 사전 훈련에 많이 쓰임
 - `Contrastive Learning`
    - 모델에게 유사한 데이터는 가깝게, 다른 데이터는 멀게 표현하도록 학습시키는 방법
    - 모델은 데이터간의 유사성을 학습하여 서로 다른 예제를 구분하는 방법

<br/>

### 모델 학습 유형

 - `Transfer Learning`
    - 이미 훈련된 모델을 다른 작업에 적용하는 방법
    - 사전 훈련된 모델은 대용량 데이터로 학습되어 다양한 특징을 추출하고, 이를 새로운 작업에 Transfer 하는 데 사용
    - 이미지 분류: 사전 훈련된 ResNet, VGG 모델을 의료 이미지 분류나 식물 종류 분류에 활용
    - 자연어 처리: GPT와 같은 모델에 자체적인 문서 분류, 감정 분석에 활용
 - `Fine Tuning Learning`
    - Transfer Learning의 한 형태로, 사전 학습된 모델을 새로운 작업에 맞게 미세 조정하는 과정
    - 모델의 일부 레이어를 고정하거나 새로운 레이어를 추가하여 작업에 맞게 모델을 파인튜닝
    - 이미지 분류: 사전 훈련된 ResNet, VGG 모델을 의료 이미지 분류나 식물 종류 분류 데이터에 학습시켜, 빠르게 모델을 학습시키고 활용
    - 자연어 처리: GPT와 같은 모델에 자체적인 문서 분류, 감정 분석 데이터에 추가 학습시켜서 활용
 - `Online Learning`
    - 데이터를 순차적으로 처리하면서 모델을 업데이트하는 방식
    - 새로운 데이터가 도착할 때마다 모델을 파인튜닝하며, 스트리밍 데이터나 지속적인 학습을 위해 유용
 - `Batch Learning`
    - 데이터 셋을 한 번에 모델에 입력하는 전통적인 방식

<br/>

## Class Imbalance

Class Imbalance란 기계 학습과 분류 문제에서 발생하는 현상 중에 하나로 클래스 간의 데이터 불균형을 나타내는 개념을 의미한다. 하나의 클래스가 다른 클래스에 비해 데이터 포인트 수가 현저히 적을 떄 발생한다. 예를 들어, 희귀 질병을 감지하는 분류 모델에서 질병이 있는 경우(양셩 클래스) 데이터가 드물게 발생하는 경우가 있다.  

Class Imbalance가 발생하는 이유로는 현실 세계의 데이터는 종종 불균형한 데이터 분포를 갖고 있으며, 데이터 수집 과정에서 클래스 불균형이 발생할 수 있다. (신용 카드 거래에서 사기 거래가 드물게 발생, 특정 클래스에 대한 샘플링 오류, 데이터 수집 방법, 라벨링 오류 등)  

Class Imbalance는 실제 ML 응용 분야에서 많이 발생하며, 이를 무시하면 심각한 문제를 초래할 수 있다.  
모델 편향: 모델이 소수 클래스를 올바르게 식별하지 못할 수 있음  
비용 고려: 소수 클래스의 중요도가 높은 경우, 이를 반영하지 않으면 예측의 비용이나 성능이 실제 상황과 맞지 않을 수 있음  
평가 지표의 왜곡: 정확도와 같은 평가 지표가 왜곡될 수 있으며, 실제 모델의 성능을 평가하기 어렵게 만듬  

<br/>

### Class Imbalance 영향

 - `Class Imbalance가 모델에 미치는 영향`
   - 모델 편향: 소수 클래스를 정확하게 예측하지 못할 가능성이 높음
   - 오분류와 비용: 소수 클래스를 무시하는 경향으로 실제에 큰 문제를 일으킬 수 있음 -> 의료 분야에서 희귀한 질병을 감지하는 모델의 경우, 해당 질병을 놓치는 것은 치명적일 수 있으므로 오분류에 따른 비용이 높을 것임

 - `모델 성능 지표에 미치는 영향`
   - 평가 지표 왜곡: Accuracy는 일반적으로 Class Imbalance에 대한 적절한 지표가 아님 -> 모든 클래스를 다수 클래스로 예측하는 "모든 예측이 부정" 이라는 간단한 전략으로높은 정확도를 얻을 수 있음
   - Accuracy 외에 percision, recall, f1-score 등의 성능 지표를 고려해야 함
   - ROC Curve and AUC
      - ROC Curve: 거짓 양성 비율에 대한 진짜 양성 비율의 변화를 시각화
      - AUC: ROC 곡선 아래 영역으로, 모델 성능을 요약하는 지표
   - 성능 지표를 신중하게 선택해야 함. 문제의 특성과 비즈니스 요구 사항에 따라 최적의 모델 평가 지표를 설정해야 함

<br/>

### Class Imbalance 다루기

Class Imbalance 조절의 목표는 소수 클래스에 대한 모델 성능을 향상시키는 것으로 오분류 비용을 줄이고 모델의 실용성을 향상 시킬 수 있다.  

Class Imbalance 조절 방법의 대분류로는 데이터 기반 접근법과 ML 알고리즘 접근법이 있다. 데이터 기반 접근법은 Resampling으로 데이터 수를 조절하여 클래스 간 균형을 맞추고, ML 알고리즘 접근법은 모델 파라미터를 조절하여 Class Imbalance를 고려하도록 모델을 튜닝하는 것이다.  

<br/>

 - `Resampling 기법`
   - __Resampling 개념__
      - 데이터의 수를 조절하여 Class Imbalance를 다루는 방법
      - 클래스간 균형을 맞추거나 OverSampling 혹은 UnderSampling을 통해 클래스를 조절
   - __Resampling 종류__
      - Over Sampling: 소수 클래스 데이터를 증가시키는 방법. 새로운 데이터 포인트를 합성하여 데이터 셋 균형을 맞춤
      - Under Sampling: 다수 클래스 데이터를 감소시키는 방법. 다수 클래스에서 일부 데이터를 제거하여 균형을 맞춤
   - __Resampling 주의사항__
      - Resampling 기법들의 장단점을 고려해야 함
      - OverSampling은 소수 클래스 데이터를 확장하지만, 데이터 중복 및 과적합 문제가 발생할 수 있음
      - UnderSampling은 다수 클래스 데이터를 줄이지만 정보 손실이 발생할 수 있음
 - `모델 튜닝 및 파라미터 조정`
   - __모델 튜닝의 필요성__
      - Class Imbalance를 고려하여 모델을 튜닝하는 과정
      - 모델은 소수 클래스를 더 잘 식별할 수 있게 해줌
   - __Weight 조정__
      - 가중치를 조절하여, 소수 클래스에 대한 높은 중요도를 부여 가능
      - 모델은 소수 클래스를 더 잘 식별할 수 있게됨
   - __Threshold 조정__
      - 분류 모델에서 임계값을 조정하여, 모델의 평가 지표를 향상시킬 수 있음
      - 예를 들어, recall을 높이기 위해 임계값을 조정할 수 있음

<br/>

### 데이터 접근 방법론 (Resampling)

#### OverSampling

 - `SMOTE (Synthetic Minority Over-Sampling)`
   - 소수 클래스 데이터 포인트들을 기존 데이터를 활용하여 데이터를 균형화하는 방법
   - 새로운 데이터 포인트는 소수 클래스 데이터 포인트와 그 주변의 이웃 데이터 포인트 사이를 보간하여 생성
   - 장점: 다양한 데이터 생성이 가능하며 모델의 일반화 능력을 향상시킬 수 있음
   - 단점: 데이터 중복이 발생할 수 있음
 - `ADASYN (Adaptive Synthetic Sampling)`
   - 소수 클래스 데이터 포인트들을 기존 데이터를 활용하여 데이터를 균형화하는 방법
   - 소수 클래스 데이터 포인트의 가중치를 계산하고, 높은 가중치를 가지는 데이터 포인트에 대해 더 많은 합성을 수행
   - 가중치는 데이터 분포와 클래스 간 거리에 따라 동적으로 조정. 거리가 가까운 데이터 포인트에 대한 합성이 더욱 강조됨
   - 장점: 데이터 분포에 더욱 더 적응적이며, 클래스 간 거리에 따라 합성을 조절하여 불균형을 더 효과적으로 다룰 수 있음
   - 단점: SMOTE에 비해 더 복잡하여 계산 비용이 높을 수 있음

<br/>

#### UnderSampling

 - `Random UnderSampling`
   - 랜덤 언더샘플링은 다수 클래스 데이터 포인트 중에서 무작위로 일부 데이터를 선택하여 소수 클래스와의 균형을 맞춤
   - 장점: 간단하고 빠르게 구현할 수 있음
   - 단점: 정보 손실이 발생할 수 있으며, 선택된 데이터가 소수 클래스를 잘 대표하지 못할 수 있음
 - `Tomek Links UnderSampling`
   - 클래스 간 거리가 가까운 데이터 포인트 쌍 중에서 다수 클래스의 데이터를 제거하는 방법
   - 수행 과정
      - 다수 클래스와 소수 클래스 사이의 모든 데이터 간의 거리를 계산
      - Tomek Links 식별: 서로 다른 클래스에 속한 데이터 포인트 쌍 중에서 클래스 간 거리가 가장 가까운 데이터 포인트 쌍을 의미
      - Tomek Links 제거: 식별된 Tomek Links를 데이터에서 제거
 - `ENN (Edited Nearest Neighbors)`
   - 클래스 간 거리가 가까운 데이터 포인트 쌍 중에서 다수 클래스의 데이터를 제거하는 방법
   - 수행 과정
      - 다수 클래스 데이터 포인트에 대해, 해당 데이터 포인트와 가장 가까운 k개의 이웃을 찾음
      - 다수 클래스 데이터 포인트 중에서 소수 클래스로 잘못 분류된 데이터 포인트를 식별
      - 이런 오분류된 데이터 포인트를 제거하여 다수 클래스 데이터를 정제
      - 모델이 잘못 분류하는 오분류 데이터를 제거하고 모델의 성능을 향상

<br/>

#### Combined Sampling

 - `SMOTEENN`
   - SMOTE와 ENN 두 기술을 함께 사용하여 클래스 불균형을 해결
   - 동작 방식
      - SMOTE를 사용한 오벗갬플링
      - ENN을 사용한 언더샘플링
      - 균형된 데이터셋 구성
   - 장점: 두 기술을 조합함으로써 클래스 불균형을 효과적으로 해결 가능
   - 단점: 모델 성능은 데이터셋의 특성과 문제에 따라 정보 손실이 발생할 수 있으며, 실험과 비교 분석 필요

<br/>

### ML 알고리즘 기반 방법론

모델 튜닝 및 파라미터 조정은 머신러닝 모델의 성능을 최적화하고 Class 불균형 데이터에 대응하기 위한 중요한 전략 중 하나이다.  
모델 알고리즘 선택, 클래스 가중치 조정, 임계값 조정, 적절한 Metric 사용, 하이퍼 파라미터 튜닝, 검증, 앙상블 등  

 - `Model Algorithm 선택`
   - Class 불균형에 Sensitive한 모델 알고리즘을 선택
   - 이진 분류에서는 SVM, Random Forest, Gradient Boosting과 같은 모델이 좋은 성능을 보임
 - `Class Weight 조정`
   - 모델의 Loss Function에 Class Weight를 부여하여 불균형한 Class에 높은 가중치(Weight)를 할당
   - 모델은 불균형 데이터셋을 더 중요하게 취급하여 학습 진행
 - `Threshold 조정`
   - 모델의 예측 Threshold를 조정하여 Precision과 Recall을 조절할 수 있음
 - `적절한 Metric 사용`
   - Accuracy가 일반적으로 불균형 Class에서 부적절하므로 다른 Metric을 기반으로 모델을 최적화
 - `Hyper-Parameter Tuning`
   - 모델의 하이퍼 파라미터를 조정하여 최적의모델을 찾음
 - `Validation`
   - Cross Validation을 통해 모델의 일반화 능력을 평가하고, Class 불균형에 대해서도 성능 신뢰성을 확인 필요
 - `Ensemble 활용`
   - 다양한 모델을 경합하는 앙상블 기법을 사용하여 Class 불균형 문제를 다룸

<br/>

## Class 불균형 성능 평가 및 선택

모델의 성능을 평가하는 것은 머신러닝 프로젝트에서 매우 중요한 부분으로 모델이 얼마나 잘 작동하고 예측을 얼마나 신뢰할 수 있는지를 판단한다.  
모델의 목적과 특성에 따라 다양한 성능 Metric을 선택할 수 있으며, 일반적으로 사용되는 Metric으로는 Accuracy, Precision, Recall, F1Score 등이 있다.  

 - `Precision (정밀도)`
   - 모델이 예측한 양성 클래스 중에서 실제로 양성인 샘플의 비율
   - 거짓 양성(FP)를 줄이고 모델이 정확한 예측을 하는 데 얼마나 잘 하는지를 나타냄
 - `Recall (재현율)`
   - 실제 양성 클래스 중에서 모델이 양성으로 예측한 샘플의 비율
   - 거짓 음성(FN)을 줄이고 모델이 실제 양성을 놓치지 않는 데 얼마나 잘 하는지를 나타냄
 - `F1-Score`
   - Precision과 Recall의 조화 평균
   - 비즈니스 목적에서 Precision과 Recall 모두 중요한 경우 활용
 - `ROC Curve`
   - 다양한 Threshold에서 모델의 Recall 대비 거짓 양성 비율을 나타내는 그래프
   - 모델의 성능을 시각적으로 평가하며, Threshold 선택의 중요성을 강조
 - `AUC`
   - AUC는 ROC 곡선 아래 영역을 나타내며, 모델의 전반적인 성능을 단일 숫자로 나타냄
   - 모델 성능을 요약할 때 유용하며, 0.5(무작위 예측) ~ 1(완벽한 예측) 사이의 값을 가짐
 - `예시`
   - 의료 진단 모델: 의료 분야에서는 Precision이 매우 중요하며, Recall도 중요한 경우가 많음. 특히 의료 진단 모델은 Class 불균형이 심하므로 주의해야 함
   - 스팸 메일 필터링: Precision과 Recall을 균형있게 유지하는 것이 중요하므로, F1-Score를 평가에 사용할 수 있음
   - Class 불균형 모델 비교: ROC Curve 혹은 AUC를 활용하여 모델 전반적인 성능을 비교


# 학습 데이터 준비 실습

 - `라이브러리 준비`
```python
# library for feature engineering and EDA
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from mpl_toolkits.mplot3d import proj3d
from IPython.display import Image
from datetime import datetime

# library for statistic
from scipy import stats
from scipy.stats import chi2_contingency
from scipy.stats import boxcox, norm
from scipy.stats import skew
from scipy.stats import kurtosis
from scipy.stats.mstats import kruskal
from scipy.stats import uniform as sp_randFloat
from scipy.stats import randint as sp_randInt
from sklearn.model_selection import RandomizedSearchCV

# library for sampling
from imblearn.over_sampling import SMOTE
from imblearn.over_sampling import ADASYN
from imblearn.combine import SMOTEENN

# library for machine learning
import sklearn
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_sample_weight
from sklearn.metrics import roc_auc_score
from sklearn.metrics import precision_recall_fscore_support
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve

from xgboost import XGBClassifier
from xgboost import plot_importance
```

<br/>

## 데이터 유형 확인

 - `정형 데이터 확인`
```python
df = pd.read_csv("./data/winequality.csv")
df.head()
```

<br/>

 - `반정형 데이터 확인`
```python
import json

# 샘플 JSON 데이터
data_str = """{
    "employees": [
        {"name": "Alice", "age": 28, "occupation": "Engineer"},
        {"name": "Bob", "age": 24, "occupation": "Data Scientist"},
        {"name": "Charlie", "age": 22, "occupation": "Designer"}
    ]
}"""

data = json.loads(data_str)
for employee in data["employees"]:
    print(employee)
```

<br/>

 - `비정형 데이터 확인`
```python
from PIL import Image

img = Image.open(path_lecture + "./data/dog_sample_image.jpeg")

# 1. 이미지 상하반전
flipped_image = img.transpose(Image.FLIP_TOP_BOTTOM)

# 2. 이미지 좌우반전
mirrored_image = img.transpose(Image.FLIP_LEFT_RIGHT)

# 이미지 축소 (반으로 축소)
width, height = img.size
shrinked_image = img.resize((width // 2, height // 2))
```

<br/>

## 데이터 샘플링

 - `가상 데이터 생성(정형)`
```python
# 가상의 데이터 생성
data = pd.DataFrame({
    'Age': np.random.randint(20, 40, 100),
    'Income': np.random.randint(50000, 100000, 100)
})
```

<br/>

 - `Random Sampling`
```python
# 무작위로 10개의 데이터 선택
random_samples = data.sample(n=10)
print(random_samples)
```

<br/>

 - `Stratified Sampling`
```python
from sklearn.model_selection import train_test_split

# 'Age' 컬럼을 기준으로 층화 샘플링
train, test = train_test_split(data, test_size=0.2, stratify=data['Age'])
print(train)
```

<br/>

 - `Cluster Sampling`
```python
# 클러스터 생성을 위해 'Age'를 기준으로 데이터 분할
data['cluster'] = pd.cut(data['Age'], bins=[20, 25, 30, 35, 40], labels=['cluster_1', 'cluster_2', 'cluster_3', 'cluster_4'])

# 무작위로 클러스터 선택
selected_cluster = np.random.choice(data['cluster'].unique())

cluster_samples = data[data['cluster'] == selected_cluster]
print(cluster_samples)
```

<br/>

 - `Weight Sampling`
```python
weights = np.random.rand(len(data))
weight_samples = data.sample(n=10, weights=weights)
print(weight_samples)
```

<br/>

 - `Importance Sampling`
```python
# 가중치 샘플링의 특별한 경우로, 특정 함수의 기대값을 추정하는 데 사용되는 샘플링 방법입
def importance_function(x):
    return x**2

weights = importance_function(data['Income'])
normalized_weights = weights / sum(weights)
importance_samples = data.sample(n=10, weights=normalized_weights)
print(importance_samples)
```

<br/>

## 데이터 라벨링에 따른 모델 학습 유형

 - `데이터 로드`
```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

data = load_iris()
```

<br/>

 - `Supervised Learning`
```python
X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2)

# 모델 학습
clf = DecisionTreeClassifier()
clf.fit(X_train, y_train)

# 예측
predictions = clf.predict(X_test)
print(predictions)
```

<br/>

 - `Un-Supervised Learning`
```python
from sklearn.cluster import KMeans

# 클러스터링 모델 학습
kmeans = KMeans(n_clusters=3)
clusters = kmeans.fit_predict(data.data)

print(clusters)
```

<br/>

 - `Semi-Supervised Learning`
```python
from sklearn.semi_supervised import LabelSpreading

# 일부 라벨만 사용
labels = np.copy(data.target)
random_unlabeled_points = np.random.rand(len(labels)) < 0.5
labels[random_unlabeled_points] = -1

# 모델 학습
lp_model = LabelSpreading()
lp_model.fit(data.data, labels)

# 예측
lp_predictions = lp_model.predict(data.data)
print(lp_predictions)
```

<br/>

## Class Imbalance

 - `Sampling for Class Imbalance`
    - 이번 실습에서는 두 가지 oversampling 기법을 활용하고, 두 가지로 만들어진 데이터를 활용하여 Model optimization 진행
    - SMOTE : Synthetic Minority Overf-sampling Technique. minority class에서 synthetic sampling을 생성하는 방법. 특정 minority class A에서 knn 기준으로 가까운 minority class Set K를 생성하고, A와 Set K 사이 간에 새로운 관측치를 생성하는 기법.
    - ADASYN : Adaptive Synthetic Sampling Approach. SMOTE는 minority class당 동일한 숫자 sample을 새롭게 생성하지만, ADASYN은 멀리 떨어진 minority class간에 더 많은 관측치를 생성
```python
# library for sampling
from imblearn.over_sampling import SMOTE
from imblearn.over_sampling import ADASYN
from imblearn.combine import SMOTEENN

# 데이터 로드
X_base = pd.read_csv(path_lecture + "data/winequality_for_class_imbalance.csv")
X_base.head()

X_base = X_base.drop('Unnamed: 0', axis=1)
Y_encoded = np.load(path_lecture + "data/winequality_for_class_imbalance_label.npy")
```

<br/>

 - `SMOTE`
```python
X_train, X_validation, y_train, y_validation = train_test_split(X_base, Y_encoded, test_size=0.25, stratify=Y_encoded)

sm = SMOTE(random_state=random_state, k_neighbors=3)
X_sm_sampling, y_sm_sampling = sm.fit_resample(X_train, y_train)

fig = plt.figure(figsize=(15,5))
fig.add_subplot(121)
sns.histplot(y_train)
plt.title("Before sampling for target label")

fig.add_subplot(122)
sns.histplot(y_sm_sampling)
plt.title("After sampling for target label")
```

<br/>

 - `ADASYN`
```python
ada = ADASYN(random_state=random_state, n_neighbors=3)
X_ada_sampling, y_ada_sampling = ada.fit_resample(X_train, y_train)

fig = plt.figure(figsize=(15,5))
fig.add_subplot(121)
sns.histplot(y_train)
plt.title("Before sampling for target label")

fig.add_subplot(122)
sns.histplot(y_ada_sampling)
plt.title("After sampling for target label")
```

# Neural Network 종류

 - 유튜브 영상: https://ebbnflow.tistory.com/119
 - 티스토리 블로그: https://ebbnflow.tistory.com/119

<br/>

## ANN (Artificial Neural Network, 인공신경망)

인공 신경망은 인간의 뇌의 작동 원리에서 영감을 받은 컴퓨터 모델입니다.  
여러 개의 뉴런(노드)이 네트워크로 연결되어 있고, 이 네트워크는 입력값을 받아 출력값을 생성하는 학습을 수행합니다.  
주로 입력층, 은닉층, 출력층으로 구성되며, 각 노드는 가중치(weight)와 활성화 함수(activation function)를 가지고 있습니다.  

<br/>

## DNN (Deep Neural Network, 심층신경망)

딥러닝은 여러 개의 은닉층을 가진 심층 신경망을 사용하는 머신 러닝 방법론입니다.  
DNN은 인공 신경망의 은닉층이 여러 개인 경우를 지칭합니다.  
일반적으로 은닉층이 많아질수록 더 복잡한 데이터 표현이 가능해지며, 높은 수준의 추상화를 학습할 수 있습니다.  

<br/>

## CNN (Convolutional Neural Network, 합성곱 신경망)

합성곱 신경망은 주로 이미지 인식과 관련된 작업에 사용되는 딥러닝의 한 유형입니다.  
CNN은 이미지의 특징을 추출하기 위해 합성곱과 풀링 연산을 사용합니다.  
합성곱 계층(convolutional layer)은 입력 이미지에 여러 필터를 적용하여 특징 맵(feature map)을 생성하고, 이를 통해 이미지의 시각적 정보를 추출합니다.  

<br/>

## RNN (Recurrent Neural Network, 순환 신경망)

순환 신경망은 순서가 있는 데이터, 예를 들어 문장이나 시계열 데이터와 같은 시퀀스 데이터를 처리하는 데 사용됩니다.  
RNN은 순환 구조를 가지며, 각 시간 단계에서 이전 단계의 출력을 현재 단계의 입력과 함께 사용합니다.  
이러한 반복 구조를 통해 RNN은 시간적인 의존성을 모델링할 수 있어 문장 생성, 번역, 시계열 예측 등에 유용하게 사용됩니다.  

<br/>

## LSTM

LSTM은 Long Short-Term Memory의 약자로, RNN(Recurrent Neural Network)의 한 종류입니다. 일반적인 RNN과 달리 LSTM은 장기 의존성 문제(Long-Term Dependencies)를 해결하기 위해 고안되었습니다.  

기본적인 RNN은 단기 메모리를 가지고 있어 시퀀스가 길어질수록 그 정보를 기억하는 능력이 감소하는 문제가 있습니다. 하지만 LSTM은 이를 극복하기 위해 게이트 메커니즘(gate mechanism)을 사용합니다.  

LSTM은 이러한 메커니즘을 통해 장기적인 의존성을 쉽게 학습할 수 있고, 따라서 긴 시퀀스 데이터에 대한 처리에 매우 효과적입니다. 이것은 자연어 처리(NLP), 음성 인식, 시계열 데이터 등과 같은 다양한 응용 분야에서 널리 사용됩니다.  
 - __Cell State (셀 상태)__
    - LSTM의 핵심이 되는 장기 상태를 나타냅니다.
    - 이 상태는 정보를 전달하기 위해 셀 전방향으로 흐르고, 정보의 추가 또는 제거를 위한 게이트 메커니즘이 적용됩니다.
 - __Forget Gate (망각 게이트)__
    - 이 게이트는 이전 셀 상태를 얼마나 잊어야 할지를 결정합니다.
    - 시그모이드 함수를 사용하여 각 상태를 0(완전히 잊음)과 1(완전히 기억) 사이의 값으로 조정합니다.
 - __Input Gate (입력 게이트)__
    - 새로운 정보를 장기 상태에 추가하기 위해 사용됩니다.
    - 두 부분으로 구성되어 있습니다.
    - 첫째, 시그모이드 함수를 사용하여 어떤 값을 업데이트할지 결정합니다.
    - 둘째, tanh 함수를 사용하여 새로운 후보 값(candidate values)을 만듭니다.
 - __Output Gate (출력 게이트)__
    - 최종 출력을 기반으로 다음 순서의 은닉 상태(hidden state)를 결정합니다.
    - 이전 숨겨진 상태와 현재 입력을 기반으로 게이트를 열고 닫습니다.

<br/>

## 요약

CNN은 이미지 특화, DNN 들어가기 전 전처리  
RNN와 LSTM은 순서 데이터 특화(자연어, 가격 예측), DNN 들어가기 전 전처리  
RNN에서 forgetting factor 추가되어 오래된 과거 데이터 영향 지운 것이 LSTM  

